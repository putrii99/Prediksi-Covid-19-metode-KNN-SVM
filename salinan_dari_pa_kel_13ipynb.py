# -*- coding: utf-8 -*-
"""Salinan dari PA_Kel.13ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1aAem52NDi9nNW1xQhPFcAe7PzP7vMNS8

#**Prediksi Tingkat Resiko Penyebaran Covid-19 pada Pulau Sumatera Menggunakan Metode K-NN dan SVM**

>Fadhilah Nur Amaliah

> Ghifary Catur Achmad

> Mohammad Luthfan Faohan

> Naila Ameera Larasati

> Nova Nurul Putri

##Import library
"""

import sklearn
import numpy as np
import pandas as pd
from sklearn.model_selection import cross_validate,cross_val_score,train_test_split
from sklearn.metrics import matthews_corrcoef
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
from sklearn.neighbors import KNeighborsClassifier
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import accuracy_score

"""##Menghubungkan colab dengan google drive dan mengimport dataset covid_sumatera """

from google.colab import drive
drive.mount('/content/drive')

dataset = pd.read_csv("/content/covid_sumatera.csv")

# Menampilkan shape dari data yg kita punya
dataset.head(10)

dataset.shape

df = dataset.drop(['kota_kabupaten'], axis = 1)
df

from sklearn.preprocessing import LabelEncoder, OneHotEncoder
#Encode untuk data kategorikal kolom kota/kabupaten

labelencoder = LabelEncoder()
df['tingkat_resiko'] = labelencoder.fit_transform(df['tingkat_resiko'])
df

df['tingkat_resiko'].value_counts()

"""##Pembagian antara data Fitur dan Label. Dari data Sumatera di atas, terdapat 4 kolom fitur (data source(x)) yang terdiri dari kota_kabupaten kasus_positif_total, total_meninggal, masih_sakit dan total_sembuh. Sedangkan data Label terdiri 1 kolom (data target(y)) yang berupa kolom tingkat_resiko"""

# Type Your Code
X = df.iloc[:,:4].values
Y = df.iloc[:,4].values

# # Type Your Code
# print ('Fitur (X):', X)
# print ('\n---------------------------------')
# print ('\nLabel (Y):', Y)

"""## Membagi dataset menjadi training set (80%) dan validation set (20%)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

> X_train: Untuk menampung data source yang akan dilatih.

> X_test: Untuk menampung data target yang akan dilatih.

> y_train: Untuk menampung data source yang akan digunakan untuk testing.

> y_test: Untuk menampung data target yang akan digunakan untuk testing.
"""

from sklearn.model_selection import train_test_split

X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size= 0.2,random_state=0)

X_train.shape, X_test.shape, Y_train.shape, Y_test.shape

"""# Melakukan Normalisasi Data

## Normalisasi data dapat dilakukan dengan menggunakan class StandarScaler. Normalisasi data dilakukan agar data yang digunakan tidak memiliki penyimpangan yang besar.
"""

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()

#fit and transform the training set
X_train = scaler.fit_transform(X_train)

# fit the test set
X_test = scaler.transform(X_test)

"""#Modelling KNN"""

# import knn
from sklearn import neighbors
from sklearn.neighbors import KNeighborsClassifier

#create KNN Classifier
knn = KNeighborsClassifier(n_neighbors=6)
#3, 4, 5, 6

#Train the model using the training sets
knn.fit(X_train, Y_train)

# Predict
y_predict = knn.predict(X_test)



"""#Confusion Matrix

confusion matrix / error matrix, membandingkan hasil klasifikasi yang dilakukan oleh sistem (model) dengan hasil klasifikasi sebenarnya. Untuk mengukur performance metrics dari confusion matrix, dapat digunakna accuracy, precission dan recall.

> Accuracy: Tingkat kedekatan nilai prediksi dengan nilai aktual (sebenarnya). Dari nilai accuracy, kita dapat menngetahui berapa persen kota yang benar diprediksi masuk kategori tingkat resiko rendah maupun tinggi.


> Precission: rasio prediksi benar positif dibandingkan dengan keseluruhan hasil yang diprediksi positif. Dari nilai Precision, kita dapat mengetahui berapa persen kota/kabupaten yang benar masuk dalam tingkat penyebaran dengan resiko tinggi dari seluruh kota/kabupaten yang diprediksi masuk ke kategori resiko tinggi.



> Recall: rasio prediksi benar positif dibandingkan dengan keseluruhan data yang benar positif. Dengan nilai Recall, kita dapat mengetahui berapa persen kota/kab yang diprediksi masuk tingkat resiko tinggi dibandingkan keseluruhan kota/kab yang sebenarnya masuk dalam resiko tinggi.
"""

from sklearn.metrics import confusion_matrix
# confusion_matrix(Y_test, y_predict)

#Import Module
from sklearn import metrics

#Show the Confusion Matrix
cm_knn = metrics.confusion_matrix(Y_test, y_predict)
cm_knn

# Show the Accuracy, Precision, Recall
acc_knn = metrics.accuracy_score(Y_test, y_predict)
prec_knn = metrics.precision_score(Y_test, y_predict, average='weighted')
rec_knn = metrics.recall_score(Y_test, y_predict, average='weighted')
f1_knn = metrics.f1_score(Y_test, y_predict, average='weighted')
kappa_knn = metrics.cohen_kappa_score(Y_test, y_predict)

print("Accuracy:", acc_knn)
print("Precision:", prec_knn)
print("Recall:", rec_knn)
print("F1 Score:", f1_knn)
print("Cohens Kappa Score:", kappa_knn)

#memvisualisasikan confusion matrix

import seaborn as sns
import matplotlib.pyplot as plt

f, ax = plt.subplots(figsize=(8,5))
sns.heatmap(metrics.confusion_matrix(Y_test, y_predict), annot=True, fmt=".0f", ax=ax)
plt.xlabel("y_head")
plt.ylabel("y_true")
plt.show()

from sklearn.metrics import classification_report

print (classification_report(Y_test, y_predict))

"""##Modelling SVM 

"""

#import svm model
from sklearn import svm

#create a scm Classifier
clf = svm.SVC(kernel='rbf') #kernel RBF
#RBF, Polynomial, Sigmoid

#Train the model using the training sets
clf.fit(X_train, Y_train)

#Predict the response for test dataset
y_pred_svm = clf.predict(X_test)

#Confusion Matrix
confusion_matrix(Y_test, y_pred_svm)

# Show the Accuracy, Precision, Recall
acc_svm = metrics.accuracy_score(Y_test,y_pred_svm)
prec_svm = metrics.precision_score(Y_test,y_pred_svm, average='weighted')
rec_svm = metrics.recall_score(Y_test,y_pred_svm, average='weighted')
f1_svm = metrics.f1_score(Y_test,y_pred_svm, average='weighted')
kappa_svm = metrics.cohen_kappa_score(Y_test,y_pred_svm)

print("Accuracy:", acc_svm)
print("Precision:", prec_svm)
print("Recall:", rec_svm)
print("F1 Score:", f1_svm)
print("Cohens Kappa Score:", kappa_svm)

#memvisualisasikan confusion matrix

import seaborn as sns
import matplotlib.pyplot as plt

f, ax = plt.subplots(figsize=(8,5))
sns.heatmap(metrics.confusion_matrix(Y_test, y_pred_svm), annot=True, fmt=".0f", ax=ax)
plt.xlabel("y_head")
plt.ylabel("y_true")
plt.show()

print(classification_report(Y_test, y_pred_svm))